{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../python_lib/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import generate_random_net\n",
    "from functions import export2matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convex_adversarial import DualNetwork\n",
    "def LP_optimizer(net,x,epsilon,c):\n",
    "    import time\n",
    "\n",
    "    '''\n",
    "    This function finds lower and upper bounds on c'*f(x+delta)\n",
    "    where norm(delta,inf)<=epsilon using the LP relaxation of\n",
    "    Wong and Kolter.\n",
    "\n",
    "    parameters:\n",
    "        net: pytorch nn sequential relu network\n",
    "        x: numpy array of size (dim_in,1) or (1,dim_in) where dim_in is the input dimension of net\n",
    "        epsilon: bound on linf norm perturbation\n",
    "        c: numpy array of size (dim_out,1) or (1,dim_out) where dim_out is the output dimension of net\n",
    "    '''\n",
    "\n",
    "    # first reshape x to a row vector and then convert it to torch tensor\n",
    "    X = torch.Tensor(x.reshape(1,-1))\n",
    "\n",
    "    #\n",
    "    C = torch.tensor([[c.reshape(1,-1)]]).type_as(X)\n",
    "    \n",
    "\n",
    "    t = time.time()\n",
    "    dual_net = DualNetwork(net,X,epsilon)\n",
    "    #ub = -dual_net(Variable(C))\n",
    "    #lb = dual_net(Variable(-C))\n",
    "    ub = -dual_net(Variable(-C))\n",
    "    lb = dual_net(Variable(C))\n",
    "    elapsed = np.asarray(time.time() - t,dtype=np.float64)\n",
    "    \n",
    "\n",
    "    lb = lb.detach().numpy().T.astype(np.float64)\n",
    "    ub = ub.detach().numpy().T.astype(np.float64)\n",
    "    \n",
    "\n",
    "    return lb,ub,elapsed\n",
    "\n",
    "# def generate_random_net(dims):\n",
    "#     '''\n",
    "#     generate a random fully-connected relu network\n",
    "#     '''\n",
    "\n",
    "#     num_layers = len(dims)-2\n",
    "#     dim_in = dims[0]\n",
    "\n",
    "#     modules = []\n",
    "\n",
    "#     for i in range(0,num_layers):\n",
    "#         param = nn.Linear(dims[i],dims[i+1])\n",
    "#         #param.weight.data = torch.from_numpy(np.random.uniform(-0.5,0.5,(dims[i+1],dims[i])))\n",
    "#         #param.bias.data = torch.from_numpy(np.random.uniform(-0.5,0.5,(dims[i+1],1)))\n",
    "#         modules.append(param)\n",
    "#         modules.append(nn.ReLU())\n",
    "\n",
    "#     param = nn.Linear(dims[-2],dims[-1])\n",
    "#     #param.weight.data = torch.from_numpy(np.random.uniform(-0.5,0.5,(dims[-1],dims[-2])))\n",
    "#     #param.bias.data = torch.from_numpy(np.random.uniform(-0.5,0.5,(dims[-1],1)))\n",
    "#     modules.append(param)\n",
    "#     net = nn.Sequential(*modules)\n",
    "\n",
    "#     return net\n",
    "\n",
    "\n",
    "def generate_random_net(dims):\n",
    "    '''\n",
    "    generate a random fully-connected relu network\n",
    "    '''\n",
    "\n",
    "    num_layers = len(dims)-2\n",
    "    dim_in = dims[0]\n",
    "\n",
    "    modules = []\n",
    "\n",
    "    for i in range(0,num_layers):\n",
    "        param = nn.Linear(dims[i],dims[i+1])\n",
    "        param.weight.data = param.weight.data * 2.0\n",
    "        #param.weight.data = torch.from_numpy(np.random.normal(0,1.0/np.sqrt(dim_in),(dims[i+1],dims[i]))).type(torch.float)\n",
    "        #param.bias.data = torch.from_numpy(np.random.normal(0,1.0,(dims[i+1],1))).type(torch.float)\n",
    "        modules.append(param)\n",
    "        modules.append(nn.ReLU())\n",
    "\n",
    "    param = nn.Linear(dims[-2],dims[-1])\n",
    "    param.weight.data = param.weight.data * 2.0\n",
    "    #param.weight.data = torch.from_numpy(np.random.normal(0,1.0/np.sqrt(dim_in),(dims[-2],dims[-1]))).type(torch.float)\n",
    "    #param.bias.data = torch.from_numpy(np.random.normal(0,1.0,(dims[-1],1))).type(torch.float)\n",
    "    modules.append(param)\n",
    "    net = nn.Sequential(*modules)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.ones((1,dim_in))\n",
    "# epsilon = 0.1\n",
    "# c = np.array([1])\n",
    "\n",
    "# net = nn.Sequential(\n",
    "#     nn.Linear(2,50),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(50,50),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(50,1),\n",
    "# )\n",
    "# lb_,ub_,time = LP_optimizer(net,x,epsilon,c)\n",
    "# lb_,ub_,time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net[0].weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_ = generate_random_net([2,50,50,1])\n",
    "# net_[0].weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lb_,ub_,time = LP_optimizer(net_,x,epsilon,c)\n",
    "# lb_,ub_,time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and Save Random Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_layers = 10\n",
    "num_nets  = 100\n",
    "num_hidden_units_per_layer = 50\n",
    "dim_in = 2\n",
    "dim_out = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "nets = {}\n",
    "generate = True\n",
    "save = True\n",
    "\n",
    "\n",
    "for num_layers in range(1,max_num_layers+1):\n",
    "    path = 'comparison/networks/'+str(num_layers)+'L/'\n",
    "    #path = str(num_layers)+'L/'\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "    for i in range(0,num_nets):\n",
    "        dims = [dim_in] + [num_hidden_units_per_layer]*num_layers + [dim_out]\n",
    "        if generate:\n",
    "            net = generate_random_net(dims)\n",
    "        if save:\n",
    "            export2matlab(path + 'random-net-'+str(num_layers)+'L-'+str(i+1),net,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = generate_random_net([2,50,50,50,50,50,1])\n",
    "#export2matlab('networks_hist/5L/random-net-5L-36',net,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.ones((1,dim_in))\n",
    "epsilon = 0.5\n",
    "c = np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "lb = np.zeros((max_num_layers,num_nets),dtype=np.float64)\n",
    "ub = np.zeros((max_num_layers,num_nets),dtype=np.float64)\n",
    "\n",
    "lb_time = np.zeros((max_num_layers,num_nets),dtype=np.float64)\n",
    "ub_time = np.zeros((max_num_layers,num_nets),dtype=np.float64)\n",
    "\n",
    "\n",
    "for num_layers in range(1,max_num_layers+1):\n",
    "    L = num_layers-1\n",
    "    for i in range(0,num_nets):\n",
    "        net = torch.load('11-06-2019/networks_small/'+str(num_layers)+'L/random-net-'+str(num_layers)+'L-'+ str(i+1) + '.pt')        \n",
    "        lb_,ub_,time = LP_optimizer(net,x,epsilon,c)\n",
    "        lb[L][i] = lb_\n",
    "        ub[L][i] = ub_\n",
    "        lb_time[L][i] = time/2.0\n",
    "        ub_time[L][i] = time/2.0\n",
    "        \n",
    "    data = {}\n",
    "    #print(lb[L][:])\n",
    "    #data['LP_'+'num_layers'+'L'] = {'lb_lp': lb[L][:], 'ub_lp': ub[L][:]}\n",
    "    data['LP_'+str(num_layers)+'L'] = ub[L][:]\n",
    "    scipy.io.savemat('11-06-2019/networks_small/'+str(num_layers)+'L/' 'LP_'+str(num_layers)+'L' + '.mat', data)\n",
    "    #print('LP_'+str(num_layers)+'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for num_layers in range(1,max_num_layers+1):\n",
    "#     L = num_layers - 1\n",
    "#     print('num_layers=' + str(num_layers) + ': lb=' + ('%.4f' % np.mean(lb[L][:])) + ' std:' + ('%.4f' % np.std(lb[L][:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_layers in range(1,max_num_layers+1):\n",
    "    L = num_layers - 1\n",
    "    print('num_layers=' + str(num_layers) + ': ub=' + ('%.4f' % np.mean(ub[L][:])) + ' std:' + ('%.4f' % np.std(ub[L][:])))\n",
    "    #print('mean(ub)='+ ('%.4f' % np.mean(ub[L][:])) + '  std(ub)=' + ('%.2f' % np.std(ub[L][:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_layers in range(1,max_num_layers+1):\n",
    "    L = num_layers - 1\n",
    "    print('num_layers=' + str(num_layers) + ': time=' + ('%.4f' % np.mean(2*lb_time[L][:])) + ' std:' + ('%.4f' % np.std(2*lb_time[L][:])))\n",
    "    #print('mean(ub)='+ ('%.4f' % np.mean(ub[L][:])) + '  std(ub)=' + ('%.2f' % np.std(ub[L][:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# worked\n",
    "#x = torch.Tensor(np.ones((1,100)))\n",
    "#c = torch.tensor([[[1]]]).type_as(x)\n",
    "#lb,ub = LP_optimizer(nets[0],x,epsilon,c)\n",
    "\n",
    "# worked-final\n",
    "# x = np.ones((1,100))\n",
    "# c = np.array([1])\n",
    "# lb,ub = LP_optimizer(nets[0],x,epsilon,c)\n",
    "# lb,ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nets = {}\n",
    "# num_nets = 10\n",
    "\n",
    "# num_layers = 9\n",
    "\n",
    "\n",
    "\n",
    "# lower_bounds = []\n",
    "# upper_bounds = []\n",
    "# lower_bounds_time = []\n",
    "# upper_bounds_time = []\n",
    "# for i in range(0,num_nets):\n",
    "#     nets[i] = torch.load('networks/'+str(num_layers)+'L/random-net-'+str(num_layers)+'L-'+ str(i+1) + '.pt')\n",
    "#     lb,ub,time = LP_optimizer(nets[i],x,epsilon,c)\n",
    "#     lower_bounds.append(lb)\n",
    "#     upper_bounds.append(ub)\n",
    "#     lower_bounds_time.append(time/2.0)\n",
    "#     upper_bounds_time.append(time/2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(lower_bounds)/len(lower_bounds),sum(lower_bounds_time)/len(lower_bounds_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(upper_bounds)/len(upper_bounds),sum(upper_bounds_time)/len(upper_bounds_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.std(np.asarray(lower_bounds)),np.std(np.asarray(lower_bounds_time)),np.std(np.asarray(upper_bounds)),np.std(np.asarray(upper_bounds_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
